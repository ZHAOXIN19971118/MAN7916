{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go!\n",
      "The Crossref server responded with status code:  200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "your_email = \"xi183728@ucf.edu\"\n",
    "if \"your_email\" in your_email:\n",
    "    print(\n",
    "        \"Nope, can't continue until you replace 'your_email@ucf.edu' with your email address in the code cell\"\n",
    "    )\n",
    "else:\n",
    "    print(\"Good to go!\")\n",
    "\n",
    "api_url = \"https://api.crossref.org/members?rows=0\"\n",
    "api_response = requests.get(api_url, headers={\"mailto\": your_email})\n",
    "print(\"The Crossref server responded with status code: \", api_response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journal_name: Journal of Applied Psychology\n",
      "ISSN: ['0021-9010', '1939-1854']\n",
      "publisher: American Psychological Association\n",
      "journal_name: Academy of Management Journal\n",
      "ISSN: ['0001-4273', '1948-0989']\n",
      "publisher: Academy of Management\n",
      "journal_name: Personnel Psychology\n",
      "ISSN: ['0031-5826', '1744-6570']\n",
      "publisher: Wiley (Blackwell Publishing)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def find_journal_issn(journal_name):\n",
    "    url = f\"https://api.crossref.org/journals?query={journal_name}&rows=5\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        items = data[\"message\"][\"items\"]\n",
    "        \n",
    "        if items:\n",
    "            journal = items[0]\n",
    "            print(f\"journal_name: {journal['title']}\")\n",
    "            print(f\"ISSN: {journal.get('ISSN', [])}\")\n",
    "            print(f\"publisher: {journal.get('publisher', '')}\")\n",
    "\n",
    "journals = [\n",
    "    \"Journal of Applied Psychology\",\n",
    "    \"Academy of Management Journal\",\n",
    "    \"Personnel Psychology\"\n",
    "]\n",
    "\n",
    "for journal in journals:\n",
    "    find_journal_issn(journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting articles for Journal of Applied Psychology (ISSN: 1939-1854)...\n",
      "Found 1441 articles. Fetching 15 pages...\n",
      "Processed page 1/15\n",
      "Processed page 2/15\n",
      "Processed page 3/15\n",
      "Processed page 4/15\n",
      "Processed page 5/15\n",
      "Processed page 6/15\n",
      "Processed page 7/15\n",
      "Processed page 8/15\n",
      "Processed page 9/15\n",
      "Processed page 10/15\n",
      "Processed page 11/15\n",
      "Processed page 12/15\n",
      "Processed page 13/15\n",
      "Processed page 14/15\n",
      "Processed page 15/15\n",
      "\n",
      "Collecting articles for Academy of Management Journal (ISSN: 1948-0989)...\n",
      "Found 819 articles. Fetching 9 pages...\n",
      "Processed page 1/9\n",
      "Processed page 2/9\n",
      "Processed page 3/9\n",
      "Processed page 4/9\n",
      "Processed page 5/9\n",
      "Processed page 6/9\n",
      "Processed page 7/9\n",
      "Processed page 8/9\n",
      "Processed page 9/9\n",
      "\n",
      "Collecting articles for Personnel Psychology (ISSN: 1744-6570)...\n",
      "Found 612 articles. Fetching 7 pages...\n",
      "Processed page 1/7\n",
      "Processed page 2/7\n",
      "Processed page 3/7\n",
      "Processed page 4/7\n",
      "Processed page 5/7\n",
      "Processed page 6/7\n",
      "Processed page 7/7\n",
      "\n",
      "Saved 2872 articles to ten_years_api.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "from typing import List, Dict\n",
    "import math\n",
    "\n",
    "class JournalCollector:\n",
    "    def __init__(self, email: str = \"your@email.com\"):\n",
    "        self.base_url = \"https://api.crossref.org/works\"\n",
    "        self.headers = {\n",
    "            'User-Agent': f'JournalCollector/1.0 (mailto:{email})'\n",
    "        }\n",
    "        self.all_articles = []\n",
    "\n",
    "    def fetch_articles(self, issn: str, rows: int = 100, offset: int = 0) -> dict:\n",
    "        \"\"\"Fetch articles with pagination\"\"\"\n",
    "        params = {\n",
    "            'filter': f'issn:{issn},from-pub-date:2015-01-01',\n",
    "            'rows': rows,\n",
    "            'offset': offset,\n",
    "            'sort': 'published',\n",
    "            'order': 'desc'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            time.sleep(1)  # Rate limiting\n",
    "            response = requests.get(self.base_url, params=params, headers=self.headers)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def extract_article_info(self, article: Dict) -> Dict:\n",
    "        \"\"\"Extract required fields from article data\"\"\"\n",
    "        try:\n",
    "            # Get publication year\n",
    "            pub_date = article.get('published')\n",
    "            if pub_date and 'date-parts' in pub_date and pub_date['date-parts']:\n",
    "                year = pub_date['date-parts'][0][0]\n",
    "            else:\n",
    "                year = None\n",
    "\n",
    "            # Extract article information\n",
    "            info = {\n",
    "                'doi': article.get('DOI'),\n",
    "                'title': article.get('title', [None])[0],\n",
    "                'references_count': article.get('references-count'),\n",
    "                'authors_count': len(article.get('author', [])),\n",
    "                'citations_count': article.get('is-referenced-by-count'),\n",
    "                'url': article.get('URL'),\n",
    "                'journal': article.get('container-title', [None])[0],\n",
    "                'abstract': article.get('abstract', ''),\n",
    "                'publication_year': year\n",
    "            }\n",
    "            return info\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting article info: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def collect_journal_articles(self, issn: str, journal_name: str):\n",
    "        \"\"\"Collect all articles for a journal since 2015\"\"\"\n",
    "        print(f\"\\nCollecting articles for {journal_name} (ISSN: {issn})...\")\n",
    "        \n",
    "        # Get total number of articles\n",
    "        initial_data = self.fetch_articles(issn, rows=1)\n",
    "        if not initial_data:\n",
    "            return\n",
    "        \n",
    "        total_results = initial_data['message']['total-results']\n",
    "        total_pages = math.ceil(total_results / 100)\n",
    "        \n",
    "        print(f\"Found {total_results} articles. Fetching {total_pages} pages...\")\n",
    "        \n",
    "        # Fetch all pages\n",
    "        for page in range(total_pages):\n",
    "            offset = page * 100\n",
    "            data = self.fetch_articles(issn, rows=100, offset=offset)\n",
    "            \n",
    "            if not data or 'message' not in data:\n",
    "                continue\n",
    "                \n",
    "            for article in data['message']['items']:\n",
    "                article_info = self.extract_article_info(article)\n",
    "                if article_info:\n",
    "                    self.all_articles.append(article_info)\n",
    "                    \n",
    "            print(f\"Processed page {page + 1}/{total_pages}\")\n",
    "\n",
    "    def save_to_csv(self, filename: str = \"ten_years_api.csv\"):\n",
    "        \"\"\"Save collected articles to CSV\"\"\"\n",
    "        if self.all_articles:\n",
    "            df = pd.DataFrame(self.all_articles)\n",
    "            df.to_csv(filename, index=False)\n",
    "            print(f\"\\nSaved {len(self.all_articles)} articles to {filename}\")\n",
    "        else:\n",
    "            print(\"No articles to save\")\n",
    "\n",
    "def main():\n",
    "    journals = [\n",
    "        {'name': 'Journal of Applied Psychology', 'issn': '1939-1854'},\n",
    "        {'name': 'Academy of Management Journal', 'issn': '1948-0989'},\n",
    "        {'name': 'Personnel Psychology', 'issn': '1744-6570'}\n",
    "    ]\n",
    "    \n",
    "    collector = JournalCollector()\n",
    "    \n",
    "    # Collect articles from each journal\n",
    "    for journal in journals:\n",
    "        collector.collect_journal_articles(journal['issn'], journal['name'])\n",
    "    \n",
    "    # Save all articles to CSV\n",
    "    collector.save_to_csv(\"ten_years_api.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete. Results saved to publication_stats.txt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from pathlib import Path\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "def analyze_publications():\n",
    "    # Read the data\n",
    "    df = pd.read_csv('ten_years_api.csv')\n",
    "    \n",
    "    # 1. Calculate correlation between publication year and citation count\n",
    "    correlation, p_value = stats.pearsonr(\n",
    "        df['publication_year'], \n",
    "        df['citations_count']\n",
    "    )\n",
    "    \n",
    "    # 2. Calculate ANOVA for journal differences\n",
    "    journals = df['journal'].unique()\n",
    "    journal_groups = [df[df['journal'] == journal]['citations_count'] \n",
    "                     for journal in journals]\n",
    "    \n",
    "    f_stat, anova_p = stats.f_oneway(*journal_groups)\n",
    "    \n",
    "    # Conduct Tukey's HSD test for post-hoc analysis\n",
    "    tukey = pairwise_tukeyhsd(\n",
    "        df['citations_count'],\n",
    "        df['journal']\n",
    "    )\n",
    "    \n",
    "    # Calculate mean citations by journal\n",
    "    journal_means = df.groupby('journal')['citations_count'].agg(['mean', 'std'])\n",
    "    \n",
    "    # Create the report\n",
    "    report = [\n",
    "        \"Publication Statistics Analysis\",\n",
    "        \"=\" * 30 + \"\\n\",\n",
    "        \"1. Correlation Analysis\",\n",
    "        \"-\" * 20,\n",
    "        f\"Correlation between publication year and citation count: {correlation:.4f}\",\n",
    "        f\"P-value: {p_value:.4f}\\n\",\n",
    "        \n",
    "        \"2. ANOVA Analysis\",\n",
    "        \"-\" * 20,\n",
    "        f\"F-statistic: {f_stat:.4f}\",\n",
    "        f\"P-value: {anova_p:.4f}\\n\",\n",
    "        \n",
    "        \"3. Mean Citations by Journal\",\n",
    "        \"-\" * 20\n",
    "    ]\n",
    "    \n",
    "    for journal in journal_means.index:\n",
    "        report.append(\n",
    "            f\"{journal}:\"\n",
    "            f\" Mean = {journal_means.loc[journal, 'mean']:.2f},\"\n",
    "            f\" SD = {journal_means.loc[journal, 'std']:.2f}\"\n",
    "        )\n",
    "    \n",
    "    report.extend([\n",
    "        \"\\n4. Tukey's HSD Post-hoc Analysis\",\n",
    "        \"-\" * 20,\n",
    "        str(tukey)\n",
    "    ])\n",
    "    \n",
    "    # Save results\n",
    "    with open('publication_stats.txt', 'w') as f:\n",
    "        f.write('\\n'.join(report))\n",
    "    \n",
    "    print(\"Analysis complete. Results saved to publication_stats.txt\")\n",
    "    \n",
    "    # Return results for potential further use\n",
    "    return {\n",
    "        'correlation': correlation,\n",
    "        'correlation_p': p_value,\n",
    "        'anova_f': f_stat,\n",
    "        'anova_p': anova_p,\n",
    "        'journal_means': journal_means,\n",
    "        'tukey': tukey\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_publications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
